{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling - Regression\n",
    "\n",
    "This notebook explores regression models to **predict Length of Stay (days)** as a baseline to the [Long Stayer Risk Stratification](https://github.com/nhsx/skunkworks-long-stayer-risk-stratification) model which achieved a Mean Absolute Error **(MAE) of 3.8 days** (2.2 median absolute error).\n",
    "\n",
    "This notebook begins with statistical tests to check the validity of linear models before implementing tree-based models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import kstest, shapiro, anderson\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [15, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_parquet(\"../../data/features.parquet\")\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cap length of stay\n",
    "\n",
    "The highest length of stay is ~250 days, so we will check the distribution of length of stay and cap high values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check distribution of length of stay\n",
    "features.groupby(by=\"LENGTH_OF_STAY\").count().AGE_ON_ADMISSION.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cap maximum length of stay to 30 days\n",
    "features.LENGTH_OF_STAY = features.LENGTH_OF_STAY.apply(lambda x: 30 if x > 30 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define target and training features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features.drop(columns=\"LENGTH_OF_STAY\")\n",
    "y = features.LENGTH_OF_STAY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance Inflaction Factors\n",
    "\n",
    "Simple linear models (ordinary least squares) assume there is no multi-collinearity.\n",
    "\n",
    "Variance inflaction factors (VIF) help quantify the extent of any collinearity present.\n",
    "\n",
    "We are looking for VIF ~< 10 across our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes ~6 minutes to run on a STANDARD_DS3_V2\n",
    "vif = pd.DataFrame()\n",
    "vif[\"feature\"] = X.columns\n",
    "\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual distributions of OLS\n",
    "\n",
    "If VIF factors indicate a lack of multi-collinearity (they do not), check for normality of residuals aka homoescadisticity.\n",
    "\n",
    "This requires training a linear model, calculating the residuals and checking visually and statistically that they are normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train basic OLS model for statistical testing only\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X, y)\n",
    "pred = pd.Series(reg.predict(X))\n",
    "resid = y - pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual inspection\n",
    "resid.hist(bins=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapiro-Wilk test for normality\n",
    "\n",
    "* Null hypothesis = our residuals are drawn from normal distribution\n",
    "* Alternate hypothesis = our residuals are not drawn from normal distribution (and fail requirements of OLS model)\n",
    "* Test statistic shows how much distribution differs to normal distribution\n",
    "* p-value is probability null hypothesis true\n",
    "* p-value < 0.05 leads us to reject null hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapiro(resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-sided Kolmogorov-Smirnov test for normality\n",
    "\n",
    "* Null hypothesis = our residuals are drawn from normal distribution\n",
    "* Alternate hypothesis = our residuals are not drawn from normal distribution (and fail requirements of OLS model)\n",
    "* Test statistic shows how much distribution differs to normal distribution\n",
    "* p-value is probability null hypothesis true\n",
    "* p-value < 0.05 leads us to reject null hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kstest(resid, \"norm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anderson-Darling test for normality\n",
    "\n",
    "* Null hypothesis = our residuals are drawn from normal distribution\n",
    "* Alternate hypothesis = our residuals are not drawn from normal distribution (and fail requirements of OLS model)\n",
    "* Test statistic is compared to critical value at the significance level required (e.g. 5%)\n",
    "* Test statistic > critical value for 5% significance level leads us to reject null hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anderson(resid, \"norm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Statistical testing invalidate assumptions for OLS models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split\n",
    "\n",
    "For model evaluation, we will hold back a 25% test set, and use cross-validation on the remaining 75% for all models until the final comparison is made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.25, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "Strategy is to try a number of regression models with:\n",
    "\n",
    "* GridsearchCV for hyperparameter tuning with cross validation, refitting full training set for best model\n",
    "* Test all final models against the held-out test set.\n",
    "\n",
    "OLS models are excluded due to statistical assumptions not being met. NN are excluded due to complexity/interpretability issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic net regression\n",
    "\n",
    "A regularised linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes ~2 seconds to run on a STANDARD_DS3_V2\n",
    "gsc = GridSearchCV(\n",
    "    estimator=linear_model.ElasticNet(),\n",
    "    param_grid={\n",
    "        \"l1_ratio\": [0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1],\n",
    "    },\n",
    "    cv=5,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    refit=True,\n",
    ")\n",
    "grid_result = gsc.fit(X_train, y_train)\n",
    "# store the performance metrics and model in a dictionary\n",
    "models = {\n",
    "    \"elastic\": {\n",
    "        \"mae_mean\": np.round(-grid_result.best_score_, 2),\n",
    "        \"model\": grid_result.best_estimator_,\n",
    "    }\n",
    "}\n",
    "models[\"elastic\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest regressor\n",
    "\n",
    "Trained without hyperparameter tuning, tree depth of 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes ~2 mins to run on a STANDARD_DS3_V2\n",
    "gsc = GridSearchCV(\n",
    "    estimator=RandomForestRegressor(),\n",
    "    param_grid={\"n_estimators\": [10, 100, 1000], \"max_depth\": [5, 10, None]},\n",
    "    cv=5,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    refit=True,\n",
    ")\n",
    "grid_result = gsc.fit(X_train, y_train)\n",
    "# store the performance metrics and model in a dictionary\n",
    "models[\"randomforest\"] = {\n",
    "    \"mae_mean\": np.round(-grid_result.best_score_, 2),\n",
    "    \"model\": grid_result.best_estimator_,\n",
    "}\n",
    "models[\"randomforest\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost\n",
    "\n",
    "Boosted tree optimised for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract categorical features\n",
    "num_features = [\n",
    "    \"AGE_ON_ADMISSION\",\n",
    "    \"EL CountLast12m\",\n",
    "    \"EMCountLast12m\",\n",
    "    \"OP First CountLast12m\",\n",
    "    \"OP FU CountLast12m\",\n",
    "]\n",
    "cat_features = list(set(X_train.columns) - set(num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes ~2 mins to run on a STANDARD_DS3_V2\n",
    "gsc = GridSearchCV(\n",
    "    estimator=CatBoostRegressor(verbose=False, cat_features=cat_features),\n",
    "    param_grid={\n",
    "        \"max_depth\": [5, 10, 16],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.5, 1],\n",
    "        \"iterations\": [10, 100, 1000],\n",
    "    },\n",
    "    cv=5,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    refit=True,\n",
    ")\n",
    "grid_result = gsc.fit(X_train, y_train)\n",
    "# store the performance metrics and model in a dictionary\n",
    "models[\"catboost\"] = {\n",
    "    \"mae_mean\": np.round(-grid_result.best_score_, 2),\n",
    "    \"model\": grid_result.best_estimator_,\n",
    "}\n",
    "models[\"catboost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = CatBoostRegressor(depth=5, verbose=False)\n",
    "cv = -cross_val_score(reg, X_train, y_train, scoring=\"neg_mean_absolute_error\", cv=5)\n",
    "# store the performance metrics in a dictionary\n",
    "models[\"catboost\"] = {\"cv_mae_mean\": cv.mean(), \"cv_mae_std\": cv.std()}\n",
    "# add the model fitted to the full training set for final testing\n",
    "models[\"catboost\"][\"model\"] = reg.fit(X_train, y_train)\n",
    "print(\n",
    "    f'Catboost MAE: {models[\"catboost\"][\"cv_mae_mean\"].round(2)} ({models[\"catboost\"][\"cv_mae_std\"].round(2)})'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = XGBRegressor(max_depth=5, random_state=42)\n",
    "cv = -cross_val_score(reg, X_train, y_train, scoring=\"neg_mean_absolute_error\", cv=5)\n",
    "# store the performance metrics in a dictionary\n",
    "models[\"xgboost\"] = {\"cv_mae_mean\": cv.mean(), \"cv_mae_std\": cv.std()}\n",
    "# add the model fitted to the full training set for final testing\n",
    "models[\"xgboost\"][\"model\"] = reg.fit(X_train, y_train)\n",
    "print(\n",
    "    f'XGBoost MAE: {models[\"xgboost\"][\"cv_mae_mean\"].round(2)} ({models[\"xgboost\"][\"cv_mae_std\"].round(2)})'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
