{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Data cleaning\n",
    "\n",
    "This notebook processes the raw data exported, following EDA and feedback with data owner.\n",
    "\n",
    "Inputs|Outputs\n",
    "---|---\n",
    "`interim/major-data.parquet`|`interim/clean-data.parquet`\n",
    "&nbsp;|`interim/cols.csv`\n",
    "&nbsp;|`interim/describe.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657726036623
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657726038326
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "major_data_df = pd.read_parquet(\"../../data/interim/major-data.parquet\")\n",
    "major_data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657726039087
    }
   },
   "outputs": [],
   "source": [
    "datetimes_df = major_data_df.copy()\n",
    "datetime_cols = [\n",
    "    \"DISCHARGE_DATE_HOSPITAL_PROVIDER_SPELL\",\n",
    "    \"EXPECTED_DISCHARGE_DATE\",\n",
    "    \"FIRST_START_DATE_TIME_WARD_STAY\",\n",
    "    \"START_DATE_TIME_HOSPITAL_PROVIDER_SPELL\",\n",
    "]\n",
    "\n",
    "for col in datetime_cols:\n",
    "    datetimes_df[col] = pd.to_datetime(datetimes_df[col], format=\"%Y-%m-%d %H:%M:%S.%f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order rows\n",
    "\n",
    "Original data is ~unordered, order by START_DATE_TIME_HOSPITAL_PROVIDER_SPELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657726039242
    }
   },
   "outputs": [],
   "source": [
    "datetimes_df.sort_values(by=\"START_DATE_TIME_HOSPITAL_PROVIDER_SPELL\", inplace=True)\n",
    "datetimes_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Drop empty/redundant/agreed columns\n",
    "\n",
    "As agreed with data SME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657726039653
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "cleaned_cols_df = (\n",
    "    datetimes_df.drop(\n",
    "        # Drop empty columns\n",
    "        columns=[\n",
    "            \"DISCHARGE_READY_DATE\",\n",
    "            \"cds_unique_identifier\",\n",
    "            \"healthcare_resource_group_code\",\n",
    "            \"presenting_complaint_code\",\n",
    "            \"ae_patient_group_code\",\n",
    "            \"ae_patient_group\",\n",
    "        ]\n",
    "    )\n",
    "    .drop(\n",
    "        # Drop redundant columns\n",
    "        columns=[\n",
    "            \"Frailty Proxy\",  # encoded in IS_frailty_proxy\n",
    "            \"all_breach_reason_codes\",  # unknown data column\n",
    "            \"ae_attendance_category_code\",  # low cardinality\n",
    "            \"all_diagnosis_codes\",  # not available on admission\n",
    "            \"all_investigation_codes\",  # not available on admission\n",
    "            \"all_local_investigation_codes\",  # not available on admission\n",
    "            \"all_local_treatment_codes\",  # not available on admission\n",
    "            \"all_treatment_codes\",  # not available on admission\n",
    "            \"PATIENT_CLASSIFICATION\",  # low cardinality\n",
    "            \"PATIENT_GENDER_CURRENT\",  # encoded in PATIENT_GENDER_CURRENT_DESCRIPTION\n",
    "            \"SOURCE_OF_ADMISSION_HOSPITAL_PROVIDER_SPELL\",  # encoded in SOURCE_OF_ADMISSION_HOSPITAL_PROVIDER_SPELL_DESCRIPTION\n",
    "            \"TREATMENT_FUNCTION_CODE_AT_ADMISSION\",  # encoded in TREATMENT_FUNCTION_CODE_AT_ADMISSION_DESCRIPTION\n",
    "            \"MAIN_SPECIALTY_CODE_AT_ADMISSION\",  # encoded in MAIN_SPECIALTY_CODE_AT_ADMISSION_DESCRIPTION\n",
    "            \"ae_initial_assessment_triage_category_code\",  # redundant given focus on major cases\n",
    "            \"ae_initial_assessment_triage_category\",  # redundant given focus on major cases\n",
    "            \"major_minor\",  # redundant given focus on major cases\n",
    "            \"manchester_triage_category\",  # redundant given focus on major cases\n",
    "            \"FIRST_START_DATE_TIME_WARD_STAY\",  # proxy for START_DATE_TIME_HOSPITAL_PROVIDER_SPELL\n",
    "            \"FIRST_REGULAR_DAY_OR_NIGHT_ADMISSION_DESCRIPTION\",  # 99.99% empty\n",
    "            \"wait\",  # not available at admission\n",
    "            \"attendance_type\",  # high cardinality (all \"E\")\n",
    "            \"initial_wait\",  # not available at admission\n",
    "            \"arrival_day_of_week\",  # will be recalculated\n",
    "            \"arrival_month_name\",  # will be recalculated\n",
    "            \"wait_minutes\",  # not available at admission\n",
    "            \"initial_wait_minutes\",  # not available at admission\n",
    "            \"FIRST_WARD_STAY_IDENTIFIER\",  # low cardinality\n",
    "            \"LENGTH_OF_STAY_IN_MINUTES\",  # low cardinality\n",
    "            \"START_DATE_HOSPITAL_PROVIDER_SPELL\",  # low cardinality\n",
    "            \"EXPECTED_DISCHARGE_DATE_TIME\",  # low cardinality\n",
    "        ]\n",
    "    )\n",
    "    .drop(\n",
    "        # Drop identifier columns\n",
    "        columns=[\n",
    "            \"LOCAL_PATIENT_IDENTIFIER\",\n",
    "            \"previous_30_day_hospital_provider_spell_number\",\n",
    "            \"ED_attendance_episode_number\",\n",
    "            \"unique_internal_ED_admission_number\",\n",
    "            \"unique_internal_IP_admission_number\",\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "cleaned_cols_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results in a reduction of ~100 columns to ~50 columns (50% reduction)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Assign nan values \n",
    "\n",
    "* SME agrees that NaN = N for stroke_ward_stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657726039847
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "cleaned_cols_df.stroke_ward_stay.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657726039994
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# fill stroke_ward_stay\n",
    "imputed_df = cleaned_cols_df.copy()\n",
    "imputed_df.stroke_ward_stay.fillna(value=\"N\", inplace=True)\n",
    "imputed_df.stroke_ward_stay.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "`MAIN_SPECIALTY_CODE_AT_ADMISSION_DESCRIPTION` is a feature that is used in modelling, and some models (Catboost) are unable to handle null values in categorical columns.\n",
    "\n",
    "There are a small number (<1%) of null values for this field, which we will encode with the string \"Not specified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657726040135
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "imputed_df.loc[\n",
    "    imputed_df.MAIN_SPECIALTY_CODE_AT_ADMISSION_DESCRIPTION.isna(),\n",
    "    \"MAIN_SPECIALTY_CODE_AT_ADMISSION_DESCRIPTION\",\n",
    "] = \"Not specified\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657726040624
    }
   },
   "outputs": [],
   "source": [
    "no_duplicate_rows_df = imputed_df.drop_duplicates()\n",
    "no_duplicate_rows_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results in a reduction of ~300 rows (0.2% reduction)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Homogenise binary fields\n",
    "\n",
    "Many fields are encoding as Y/N or similar, convert these into binary fields using an explicit mapping.\n",
    "\n",
    "Once mapped, check for NaN values and revert to Data SME to make sure we are not infilling values without correct clinical understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657726040784
    }
   },
   "outputs": [],
   "source": [
    "no_duplicate_rows_df.IS_care_home_on_admission.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657726040921
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "binary_fields_df = no_duplicate_rows_df.copy()\n",
    "# map Y/N to 1/0 for non-null columns\n",
    "binary_cols = [\n",
    "    \"stroke_ward_stay\",\n",
    "    \"IS_care_home_on_admission\",\n",
    "    \"IS_care_home_on_discharge\",\n",
    "]\n",
    "for col in binary_cols:\n",
    "    binary_fields_df[col] = binary_fields_df[col].map({\"Y\": 1, \"N\": 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `IS_illness_not_injury` field is a binary field that uses the strings `Illness` and `Injury` to define its state. We will create a true binary field (`0` or `1`) to encode this information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657726041066
    }
   },
   "outputs": [],
   "source": [
    "# create new fields\n",
    "binary_fields_df[\"IS_illness_not_injury\"] = binary_fields_df[\"Illness Injury Flag\"].map(\n",
    "    {\"Illness\": 1, \"Injury\": 0}\n",
    ")\n",
    "# drop old fields\n",
    "binary_fields_df.drop(columns=[\"Illness Injury Flag\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657726041214
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# check new binary fields\n",
    "# if you have any NaN values you need to check with Data SME on how to fill them ie. default Y or N?\n",
    "for field in [\n",
    "    \"stroke_ward_stay\",\n",
    "    \"IS_care_home_on_admission\",\n",
    "    \"IS_care_home_on_discharge\",\n",
    "    \"IS_illness_not_injury\",\n",
    "]:\n",
    "    print(binary_fields_df[field].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Check genders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657726041516
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# What is the distribution of gender in the dataset?\n",
    "binary_fields_df.PATIENT_GENDER_CURRENT_DESCRIPTION.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, there are three possible values for gender: Male, Female and \"Not specified\".\n",
    "\n",
    "Only 9 rows of data correspond to \"Not specified\", which represents less than 0.01% of the data.\n",
    "\n",
    "We choose to remove these rows as the sample size is too small to be reliably modelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657726041673
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# drop \"not specified\" values\n",
    "genders_df = binary_fields_df.drop(\n",
    "    labels=binary_fields_df[\n",
    "        binary_fields_df.PATIENT_GENDER_CURRENT_DESCRIPTION == \"Not specified\"\n",
    "    ].index\n",
    ")\n",
    "genders_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cap length of stay\n",
    "\n",
    "What is the distribution of length of stay, and should we cap high length of stay outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657726042006
    }
   },
   "outputs": [],
   "source": [
    "# Check distribution of length of stay\n",
    "genders_df.groupby(by=\"LENGTH_OF_STAY\").count().AGE_ON_ADMISSION.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest length of stay is ~250 days, with the number of patients with length of stay over 30 days decreasing significantly.\n",
    "\n",
    "The original work capped length of stay to 30 days, and we will do the same here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657726042160
    }
   },
   "outputs": [],
   "source": [
    "# Cap maximum length of stay to 30 days\n",
    "capped_df = genders_df.copy()\n",
    "capped_df.LENGTH_OF_STAY = capped_df.LENGTH_OF_STAY.apply(lambda x: 30 if x > 30 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final data checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657726042890
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# check null values\n",
    "# there are still some columns with null values; these can be encoding during modelling using e.g. dummy_na=True\n",
    "capped_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657726055714
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# plot null values\n",
    "sns.set(rc={\"figure.figsize\": (15, 8)})\n",
    "sns.heatmap(capped_df.isnull(), cbar=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657726057189
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Export data (outside git tree)\n",
    "capped_df.to_parquet(\"../../data/interim/clean-data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657726057626
    }
   },
   "outputs": [],
   "source": [
    "# Export cols/descriptions for Data Dictionary Excel/Google Sheets import (outside git tree)\n",
    "capped_df.dtypes.to_csv(\"../../data/interim/cols.csv\")\n",
    "capped_df.describe().to_csv(\"../../data/interim/describe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
