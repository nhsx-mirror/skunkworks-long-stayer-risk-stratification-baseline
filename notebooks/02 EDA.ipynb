{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 Exploratory Data Analysis\n",
    "\n",
    "Notebook goal: initial Exploratory Data Analysis to understand columns (features), data cleanliness and basic (inter)correlations:\n",
    "\n",
    "1. Check data types of columns and re-cast if necessary\n",
    "2. Check validity of LENGTH_OF_STAY column\n",
    "3. Check ordering of dataset\n",
    "4. Check levels of missing data\n",
    "4. Check levels of duplication of dataset\n",
    "5. Basic correlation to look at relationships between columns\n",
    "6. Generate a pandas profile and explore distributions of data\n",
    "\n",
    "Note that EDA is a cyclical process, and many explorations of the data take place after cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1655732306976
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data\n",
    "\n",
    "Data processed in previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1655732312419
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Load into pandas\n",
    "original_data_df = pd.read_parquet(\"../../data/raw/original-data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Explore Data types\n",
    "\n",
    "Check the range of data types in the dataset manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1655732312655
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "original_data_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two derived fields, `arrival_day_of_week` and `arrival_month_name` - how have they been derived?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1655732312845
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "original_data_df.arrival_day_of_week.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1655732313044
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "original_data_df.arrival_month_name.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data consistency checks\n",
    "\n",
    "Does the LENGTH_OF_STAY match start/end dates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1655732313238
    }
   },
   "outputs": [],
   "source": [
    "# check data types before conducting maths\n",
    "original_data_df[\n",
    "    [\n",
    "        \"DISCHARGE_DATE_HOSPITAL_PROVIDER_SPELL\",\n",
    "        \"START_DATE_TIME_HOSPITAL_PROVIDER_SPELL\",\n",
    "    ]\n",
    "].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1655732314006
    }
   },
   "outputs": [],
   "source": [
    "# cast dates to datetime\n",
    "datetime_df = original_data_df.copy()\n",
    "datetime_df.DISCHARGE_DATE_HOSPITAL_PROVIDER_SPELL = pd.to_datetime(\n",
    "    datetime_df.DISCHARGE_DATE_HOSPITAL_PROVIDER_SPELL, format=\"%Y-%m-%d %H:%M:%S.%f\"\n",
    ")\n",
    "datetime_df.START_DATE_TIME_HOSPITAL_PROVIDER_SPELL = pd.to_datetime(\n",
    "    datetime_df.START_DATE_TIME_HOSPITAL_PROVIDER_SPELL, format=\"%Y-%m-%d %H:%M:%S.%f\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1655732314194
    }
   },
   "outputs": [],
   "source": [
    "# Discharge is whole day, admission is datetime\n",
    "datetime_df[\n",
    "    [\n",
    "        \"DISCHARGE_DATE_HOSPITAL_PROVIDER_SPELL\",\n",
    "        \"START_DATE_TIME_HOSPITAL_PROVIDER_SPELL\",\n",
    "    ]\n",
    "].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1655732314378
    }
   },
   "outputs": [],
   "source": [
    "# calculate derived LoS\n",
    "# round up to whole days\n",
    "datetime_df[\"DER_los\"] = (\n",
    "    datetime_df[\"DISCHARGE_DATE_HOSPITAL_PROVIDER_SPELL\"]\n",
    "    - datetime_df[\"START_DATE_TIME_HOSPITAL_PROVIDER_SPELL\"]\n",
    ").dt.days + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1655732314558
    }
   },
   "outputs": [],
   "source": [
    "# quick visual inspection - do they match?\n",
    "datetime_df[[\"DER_los\", \"LENGTH_OF_STAY\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1655732314752
    }
   },
   "outputs": [],
   "source": [
    "# check that mean difference is ~ 0 days\n",
    "datetime_df[[\"DER_los\", \"LENGTH_OF_STAY\"]].diff(axis=1).LENGTH_OF_STAY.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Data ordering\n",
    "\n",
    "How is data ordered?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1655732314935
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# not ordered by local patient id\n",
    "datetime_df.LOCAL_PATIENT_IDENTIFIER.head(10)\n",
    "\n",
    "# nb. value_counts() shows repeat visits - could this be feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1655732315120
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# not ordered by start-date\n",
    "datetime_df.START_DATE_TIME_HOSPITAL_PROVIDER_SPELL.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1655732315305
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# not by end-date\n",
    "datetime_df.DISCHARGE_DATE_HOSPITAL_PROVIDER_SPELL.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1655732315490
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# not by cds\n",
    "datetime_df.cds_unique_identifier.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Re-order data by `START_DATE_TIME_HOSPITAL_PROVIDER_SPELL`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1655732315773
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "datetime_df.sort_values(by=\"START_DATE_TIME_HOSPITAL_PROVIDER_SPELL\", inplace=True)\n",
    "datetime_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Explore Missing data\n",
    "\n",
    "We can generate a heatmap of missing data to quickly visualise the totality of missing data in one image. This will only capture significant areas of missing data, but can be useful to identify sparse columns, rows and blocks of missing data.\n",
    "\n",
    "The heatmap generated will show missing data in black, and present data in white.\n",
    "\n",
    "Any patches of black indicate missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1655732403845
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (15, 8)})\n",
    "sns.heatmap(datetime_df.isnull(), cbar=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also summarise the number of missing rows of data in tabular format, which can help identify columns with smaller amounts of missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1655732321888
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "datetime_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The population for this project is major, non-elective cases. The `IS_major` field capture major cases, but we want to check how complete it is as it will be used to define the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1655732322276
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "datetime_df.IS_major.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, we want to check the `elective_or_non_elective` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_df.elective_or_non_elective.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Identify early block of missing data\n",
    "\n",
    "The first ~100k rows (from visual plot) are missing a significant amount of data - is this due to the introduction of a new system?\n",
    "\n",
    "1. Which columns are missing?\n",
    "1. When does the block of missing data end? Does this align with a new clinical system?\n",
    "\n",
    "Visually, a one column is that is indicative of the missing data is `wait_minutes`. We will use this column as an indicator for the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1655734076045
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# extract roughly the missing block\n",
    "missing_block_df = datetime_df.iloc[0:120000]\n",
    "# which columns are null when wait_minutes is null?\n",
    "missing_rows_df = missing_block_df[missing_block_df.wait_minutes.isna()]\n",
    "# calculate proportion of missing rows\n",
    "missing_fields_df = pd.DataFrame(missing_rows_df.isna().sum().reset_index())\n",
    "missing_fields_df.columns = [\"field\", \"null_count\"]\n",
    "missing_fields_df[\"null_prop\"] = (\n",
    "    missing_fields_df[\"null_count\"] / missing_rows_df.shape[0]\n",
    ")\n",
    "# select columns that have between 95% and 101% missing rows, to capture similar levels of missing data\n",
    "missing_fields_df[missing_fields_df.null_prop.between(0.95, 1.01)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Roughly 39 columns are missing similar levels of data to `wait_minutes` in the first 120,000 rows of data.\n",
    "\n",
    "These align with the introduction of a new system. \n",
    "\n",
    "We will identify which row index this system was introduced, visually then by reviewing the data by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1655722788340
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Plot an interactive view of single column around where the gap starts\n",
    "# Use plotly zoom functionality to identify where the missing data ends\n",
    "fig = px.line(\n",
    "    datetime_df.iloc[100000:120000],\n",
    "    x=datetime_df.iloc[100000:120000].index,\n",
    "    y=\"wait_minutes\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Check on the area of interest by examining values by hand, in a tabular format. We are looking for the start of a continuous presence of the `wait_minutes` feature, bearing in mind the column is semi-sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1655722881902
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "datetime_df.iloc[109500:110000].wait_minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "After inspection by eye (plot) and by hand (table) we define index `109894` as the start of \"good quality data\", based on the presence of `wait_minutes` data which is indicative of the missing columns at the start of the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Correlation plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1650383929706
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Pearson correlation by default:\n",
    "corr = datetime_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1650383930713
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    mask=mask,\n",
    "    cmap=cmap,\n",
    "    vmax=0.3,\n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={\"shrink\": 0.5},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for correlation between features\n",
    "corr[corr != 1.00][corr.abs() > 0.1].abs().unstack().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for correlation with LENGTH OF STAY\n",
    "corr.LENGTH_OF_STAY[corr.LENGTH_OF_STAY.abs().sort_values(ascending=False).index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Check duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Check duplicate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How is FIRST_START_DATE_TIME_WARD_STAY different to START_DATE_TIME_HOSPITAL_PROVIDER_SPELL?\n",
    "# Cast FIRST_START_DATE_TIME_WARD_STAY to datetime\n",
    "datetime_df.FIRST_START_DATE_TIME_WARD_STAY = pd.to_datetime(\n",
    "    datetime_df.FIRST_START_DATE_TIME_WARD_STAY, format=\"%Y-%m-%d %H:%M:%S.%f\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1650383941306
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# check if FIRST_START_DATE_TIME_WARD_STAY is the same as START_DATE_TIME_HOSPITAL_PROVIDER_SPELL\n",
    "datetime_df.FIRST_START_DATE_TIME_WARD_STAY.equals(\n",
    "    datetime_df.START_DATE_TIME_HOSPITAL_PROVIDER_SPELL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1650383941531
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# they are different, so work out what the difference is between the columns\n",
    "datetime_df[\n",
    "    [\"FIRST_START_DATE_TIME_WARD_STAY\", \"START_DATE_TIME_HOSPITAL_PROVIDER_SPELL\"]\n",
    "].sample(10).diff(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1650383941736
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# there are many NaT values in FIRST_START_DATE_TIME_WARD_STAY which lead to a difference of 0 days\n",
    "# find out if there are any actual differences in dates\n",
    "(\n",
    "    datetime_df[\n",
    "        [\"FIRST_START_DATE_TIME_WARD_STAY\", \"START_DATE_TIME_HOSPITAL_PROVIDER_SPELL\"]\n",
    "    ]\n",
    "    .diff(axis=1)\n",
    "    .START_DATE_TIME_HOSPITAL_PROVIDER_SPELL\n",
    "    > pd.Timedelta(0)\n",
    ").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Pandas profiling\n",
    "\n",
    "Pandas profiling will (after some time) generate an overall profile of the dataset, including histograms, frequent values and checks such as sparsity and ordinality that can help generate further questions for the data subject matter expert (SME)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1650383942718
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "pd.__version__\n",
    "# note bug with version 1.4.1: https://github.com/ydataai/pandas-profiling/issues/911\n",
    "# use lower version (e.g. 1.3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1650383942909
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Dataset large and crashing without minimal=True\n",
    "profile = ProfileReport(datetime_df, title=\"Pandas Profiling Report\", minimal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1650383994203
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
  },
  "kernel_info": {
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
