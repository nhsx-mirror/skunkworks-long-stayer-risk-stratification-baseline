{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 Exploratory Data Analysis\n",
    "\n",
    "Notebook goal: initial Exploratory Data Analysis to understand columns (features), data cleanliness and basic (inter)correlations:\n",
    "\n",
    "1. Check data types of columns and re-cast if necessary\n",
    "2. Check validity of LENGTH_OF_STAY column\n",
    "3. Check ordering of dataset\n",
    "4. Check levels of missing data\n",
    "4. Check levels of duplication of dataset\n",
    "5. Basic correlation to look at relationships between columns\n",
    "6. Generate a pandas profile and explore distributions of data\n",
    "\n",
    "Note that EDA is a cyclical process, and many explorations of the data take place after cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657725231229
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Data processed in previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657725267284
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Load into pandas\n",
    "original_data_df = pd.read_parquet(\"../../data/raw/original-data.parquet\")\n",
    "original_data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Remove minor and elective cases\n",
    "\n",
    "The modelling in this project is focussed on major, non-elective cases, and these cases will tend to have a higher length of stay and subsequent risk of becoming a long stayer.\n",
    "\n",
    "We will remove minor and elective cases before proceeding with further exploration.\n",
    "\n",
    "Data subject matter expert (SME) has clarified that Null values for `IS_MAJOR` are \"N\", so we can select only \"Y\" values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657725269524
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "major_df = original_data_df[original_data_df.IS_major == \"Y\"]\n",
    "major_df = major_df[major_df.elective_or_non_elective == \"Non-elective admission\"]\n",
    "# drop now-redundant columns\n",
    "major_df.drop(columns=[\"IS_major\", \"elective_or_non_elective\"], inplace=True)\n",
    "major_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Explore Data types\n",
    "\n",
    "Check the range of data types in the dataset manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657725277032
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "major_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two derived fields, `arrival_day_of_week` and `arrival_month_name` - how have they been derived?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657725278985
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "major_df.arrival_day_of_week.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657725279976
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "major_df.arrival_month_name.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data consistency checks\n",
    "\n",
    "Does the LENGTH_OF_STAY match start/end dates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657725281397
    }
   },
   "outputs": [],
   "source": [
    "# check data types before conducting maths\n",
    "major_df[\n",
    "    [\n",
    "        \"DISCHARGE_DATE_HOSPITAL_PROVIDER_SPELL\",\n",
    "        \"START_DATE_TIME_HOSPITAL_PROVIDER_SPELL\",\n",
    "    ]\n",
    "].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657725282867
    }
   },
   "outputs": [],
   "source": [
    "# cast dates to datetime\n",
    "datetime_df = major_df.copy()\n",
    "datetime_df.DISCHARGE_DATE_HOSPITAL_PROVIDER_SPELL = pd.to_datetime(\n",
    "    datetime_df.DISCHARGE_DATE_HOSPITAL_PROVIDER_SPELL, format=\"%Y-%m-%d %H:%M:%S.%f\"\n",
    ")\n",
    "datetime_df.START_DATE_TIME_HOSPITAL_PROVIDER_SPELL = pd.to_datetime(\n",
    "    datetime_df.START_DATE_TIME_HOSPITAL_PROVIDER_SPELL, format=\"%Y-%m-%d %H:%M:%S.%f\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657725283625
    }
   },
   "outputs": [],
   "source": [
    "# Discharge is whole day, admission is datetime\n",
    "datetime_df[\n",
    "    [\n",
    "        \"DISCHARGE_DATE_HOSPITAL_PROVIDER_SPELL\",\n",
    "        \"START_DATE_TIME_HOSPITAL_PROVIDER_SPELL\",\n",
    "    ]\n",
    "].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657725284925
    }
   },
   "outputs": [],
   "source": [
    "# calculate derived LoS\n",
    "# round up to whole days\n",
    "datetime_df[\"DER_los\"] = (\n",
    "    datetime_df[\"DISCHARGE_DATE_HOSPITAL_PROVIDER_SPELL\"]\n",
    "    - datetime_df[\"START_DATE_TIME_HOSPITAL_PROVIDER_SPELL\"]\n",
    ").dt.days + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657725285434
    }
   },
   "outputs": [],
   "source": [
    "# quick visual inspection - do they match?\n",
    "datetime_df[[\"DER_los\", \"LENGTH_OF_STAY\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657725287048
    }
   },
   "outputs": [],
   "source": [
    "# check that mean difference is ~ 0 days\n",
    "datetime_df[[\"DER_los\", \"LENGTH_OF_STAY\"]].diff(axis=1).LENGTH_OF_STAY.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Data ordering\n",
    "\n",
    "How is data ordered?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657725290882
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# not ordered by local patient id\n",
    "datetime_df.LOCAL_PATIENT_IDENTIFIER.head(10)\n",
    "\n",
    "# nb. value_counts() shows repeat visits - could this be feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657725291838
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# not ordered by start-date\n",
    "datetime_df.START_DATE_TIME_HOSPITAL_PROVIDER_SPELL.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657725293844
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# not by end-date\n",
    "datetime_df.DISCHARGE_DATE_HOSPITAL_PROVIDER_SPELL.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657725297165
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# not by cds\n",
    "datetime_df.cds_unique_identifier.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Re-order data by `START_DATE_TIME_HOSPITAL_PROVIDER_SPELL`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657725301755
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "datetime_df.sort_values(by=\"START_DATE_TIME_HOSPITAL_PROVIDER_SPELL\", inplace=True)\n",
    "datetime_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Explore Missing data\n",
    "\n",
    "We can generate a heatmap of missing data to quickly visualise the totality of missing data in one image. This will only capture significant areas of missing data, but can be useful to identify sparse columns, rows and blocks of missing data.\n",
    "\n",
    "The heatmap generated will show missing data in black, and present data in white.\n",
    "\n",
    "Any patches of black indicate missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657725321372
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (15, 8)})\n",
    "sns.heatmap(datetime_df.isnull(), cbar=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also summarise the number of missing rows of data in tabular format, which can help identify columns with smaller amounts of missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657725332979
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "datetime_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Correlation plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657725365478
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Pearson correlation by default:\n",
    "corr = datetime_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657725369403
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    mask=mask,\n",
    "    cmap=cmap,\n",
    "    vmax=0.3,\n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={\"shrink\": 0.5},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657725395011
    }
   },
   "outputs": [],
   "source": [
    "# check for correlation between features\n",
    "corr[corr != 1.00][corr.abs() > 0.1].abs().unstack().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657725402096
    }
   },
   "outputs": [],
   "source": [
    "# check for correlation with LENGTH OF STAY\n",
    "corr.LENGTH_OF_STAY[corr.LENGTH_OF_STAY.abs().sort_values(ascending=False).index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Check duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657725412558
    }
   },
   "outputs": [],
   "source": [
    "datetime_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Check duplicate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657725414119
    }
   },
   "outputs": [],
   "source": [
    "# How is FIRST_START_DATE_TIME_WARD_STAY different to START_DATE_TIME_HOSPITAL_PROVIDER_SPELL?\n",
    "# Cast FIRST_START_DATE_TIME_WARD_STAY to datetime\n",
    "datetime_df.FIRST_START_DATE_TIME_WARD_STAY = pd.to_datetime(\n",
    "    datetime_df.FIRST_START_DATE_TIME_WARD_STAY, format=\"%Y-%m-%d %H:%M:%S.%f\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657725415959
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# check if FIRST_START_DATE_TIME_WARD_STAY is the same as START_DATE_TIME_HOSPITAL_PROVIDER_SPELL\n",
    "datetime_df.FIRST_START_DATE_TIME_WARD_STAY.equals(\n",
    "    datetime_df.START_DATE_TIME_HOSPITAL_PROVIDER_SPELL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657725417747
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# they are different, so work out what the difference is between the columns\n",
    "datetime_df[\n",
    "    [\"FIRST_START_DATE_TIME_WARD_STAY\", \"START_DATE_TIME_HOSPITAL_PROVIDER_SPELL\"]\n",
    "].sample(10).diff(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657725424757
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# there are many NaT values in FIRST_START_DATE_TIME_WARD_STAY which lead to a difference of 0 days\n",
    "# find out if there are any actual differences in dates\n",
    "(\n",
    "    datetime_df[\n",
    "        [\"FIRST_START_DATE_TIME_WARD_STAY\", \"START_DATE_TIME_HOSPITAL_PROVIDER_SPELL\"]\n",
    "    ]\n",
    "    .diff(axis=1)\n",
    "    .START_DATE_TIME_HOSPITAL_PROVIDER_SPELL\n",
    "    > pd.Timedelta(0)\n",
    ").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Pandas profiling\n",
    "\n",
    "Pandas profiling will (after some time) generate an overall profile of the dataset, including histograms, frequent values and checks such as sparsity and ordinality that can help generate further questions for the data subject matter expert (SME)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1650383942718
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "pd.__version__\n",
    "# note bug with version 1.4.1: https://github.com/ydataai/pandas-profiling/issues/911\n",
    "# use lower version (e.g. 1.3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1650383942909
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Dataset large and crashing without minimal=True\n",
    "profile = ProfileReport(datetime_df, title=\"Pandas Profiling Report\", minimal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1650383994203
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Export data\n",
    "\n",
    "This is the data containing our target population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1657726022830
    }
   },
   "outputs": [],
   "source": [
    "# nb. this is outside the git tree\n",
    "major_df.to_parquet(\"../../data/interim/major-data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
  },
  "kernel_info": {
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
