{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Data cleaning\n",
    "\n",
    "This notebook processes the raw data exported, following EDA and feedback with data owner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1650960469668
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1650960488979
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "original_data_df = pd.read_parquet(\"../../data/original-data.parquet\")\n",
    "original_data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetimes_df = original_data_df.copy()\n",
    "datetime_cols = [\n",
    "    \"DISCHARGE_DATE_HOSPITAL_PROVIDER_SPELL\",\n",
    "    \"EXPECTED_DISCHARGE_DATE\",\n",
    "    \"FIRST_START_DATE_TIME_WARD_STAY\",\n",
    "    \"START_DATE_TIME_HOSPITAL_PROVIDER_SPELL\",\n",
    "]\n",
    "\n",
    "for col in datetime_cols:\n",
    "    datetimes_df[col] = pd.to_datetime(datetimes_df[col], format=\"%Y-%m-%d %H:%M:%S.%f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order rows\n",
    "\n",
    "Original data is ~unordered, order by START_DATE_TIME_HOSPITAL_PROVIDER_SPELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetimes_df.sort_values(by=\"START_DATE_TIME_HOSPITAL_PROVIDER_SPELL\", inplace=True)\n",
    "datetimes_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Drop early rows missing data\n",
    "\n",
    "As explored during EDA, there is a section of ~110k rows missing data due to the introduction of a new clinical system.\n",
    "\n",
    "Once ordered by admission, this section appears at the start. Remove these rows rather than impute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing rows appear at start\n",
    "datetimes_df.wait_minutes.isnull().map({True: 1, False: 0}).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove null values in first 110,000 values, and append the remaining values into a new dataframe\n",
    "modern_data_df = datetimes_df[datetimes_df.index < 110000].dropna(\n",
    "    axis=0, subset=[\"wait_minutes\"]\n",
    ")\n",
    "modern_data_df = pd.concat(\n",
    "    [modern_data_df, datetimes_df[datetimes_df.index >= 110000]]\n",
    ").reset_index(drop=True)\n",
    "# Visualise remaining rows\n",
    "modern_data_df.wait_minutes.isnull().map({True: 1, False: 0}).plot()\n",
    "modern_data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Drop empty/redundant/agreed columns\n",
    "\n",
    "As agreed with data SME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1650448162485
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "cleaned_cols_df = (\n",
    "    modern_data_df.drop(\n",
    "        # Drop empty columns\n",
    "        columns=[\n",
    "            \"DISCHARGE_READY_DATE\",\n",
    "            \"cds_unique_identifier\",\n",
    "            \"healthcare_resource_group_code\",\n",
    "            \"presenting_complaint_code\",\n",
    "            \"ae_patient_group_code\",\n",
    "            \"ae_patient_group\",\n",
    "        ]\n",
    "    )\n",
    "    .drop(\n",
    "        # Drop redundant columns\n",
    "        columns=[\n",
    "            \"Frailty Proxy\",\n",
    "            \"all_breach_reason_codes\",\n",
    "            \"ae_attendance_category_code\",\n",
    "            \"all_diagnosis_codes\",\n",
    "            \"all_investigation_codes\",\n",
    "            \"all_local_investigation_codes\",\n",
    "            \"all_local_treatment_codes\",\n",
    "            \"all_treatment_codes\",\n",
    "            \"PATIENT_CLASSIFICATION\",\n",
    "            \"PATIENT_GENDER_CURRENT\",\n",
    "            \"SOURCE_OF_ADMISSION_HOSPITAL_PROVIDER_SPELL\",\n",
    "            \"TREATMENT_FUNCTION_CODE_AT_ADMISSION\",\n",
    "            \"MAIN_SPECIALTY_CODE_AT_ADMISSION\",\n",
    "            \"ae_initial_assessment_triage_category_code\",\n",
    "            \"ae_initial_assessment_triage_category\",\n",
    "            \"major_minor\",\n",
    "            \"manchester_triage_category\",\n",
    "            \"FIRST_START_DATE_TIME_WARD_STAY\",\n",
    "            \"FIRST_REGULAR_DAY_OR_NIGHT_ADMISSION_DESCRIPTION\",\n",
    "            \"wait\",\n",
    "            \"attendance_type\",\n",
    "            \"initial_wait\",\n",
    "            \"arrival_day_of_week\",\n",
    "            \"arrival_month_name\",\n",
    "        ]\n",
    "    )\n",
    "    .drop(\n",
    "        # Drop identifier columns\n",
    "        columns=[\n",
    "            \"LOCAL_PATIENT_IDENTIFIER\",\n",
    "            \"previous_30_day_hospital_provider_spell_number\",\n",
    "            \"ED_attendance_episode_number\",\n",
    "            \"unique_internal_ED_admission_number\",\n",
    "            \"unique_internal_IP_admission_number\",\n",
    "        ]\n",
    "    )\n",
    "    .drop(\n",
    "        # Drop low cardinality columns\n",
    "        columns=[\n",
    "            \"FIRST_WARD_STAY_IDENTIFIER\",\n",
    "            \"LENGTH_OF_STAY_IN_MINUTES\",\n",
    "            \"START_DATE_HOSPITAL_PROVIDER_SPELL\",\n",
    "            \"EXPECTED_DISCHARGE_DATE_TIME\",\n",
    "        ]\n",
    "    )\n",
    "    .drop(\n",
    "        # Drop less useful columns\n",
    "        columns=[\"wait_minutes\", \"initial_wait_minutes\"]\n",
    "    )\n",
    ")\n",
    "cleaned_cols_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Assign nan values \n",
    "\n",
    "* SME agrees that NaN = N for stroke_ward_stay\n",
    "* SME agrees that None = N for IS_MAJOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1650448209112
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "cleaned_cols_df.stroke_ward_stay.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1650448209355
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# fill stroke_ward_stay\n",
    "imputed_df = cleaned_cols_df.copy()\n",
    "imputed_df.stroke_ward_stay.fillna(value=\"N\", inplace=True)\n",
    "imputed_df.stroke_ward_stay.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1650448209628
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "imputed_df.IS_major.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1650448209828
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# fill IS_major\n",
    "imputed_df.IS_major.fillna(value=\"N\", inplace=True)\n",
    "imputed_df.IS_major.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Drop sparse rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1650448285559
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# check for null values across dataset\n",
    "imputed_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1650448611763
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# some columns have < 1000 null values, and a larger subset have ~68000 missing. Drop these\n",
    "removed_sparse_rows_df = imputed_df.dropna(\n",
    "    subset=[\n",
    "        \"ADMISSION_METHOD_HOSPITAL_PROVIDER_SPELL_DESCRIPTION\",\n",
    "        \"EXPECTED_DISCHARGE_DATE\",\n",
    "        \"MAIN_SPECIALTY_CODE_AT_ADMISSION_DESCRIPTION\",\n",
    "        \"POST_CODE_AT_ADMISSION_DATE_DISTRICT\",\n",
    "        \"IMD county decile\",\n",
    "        \"all_diagnoses\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_duplicate_rows_df = removed_sparse_rows_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Homogenise binary fields\n",
    "\n",
    "Many fields are encoding as Y/N or similar, convert these into binary fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1650449146256
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "binary_fields_df = no_duplicate_rows_df.copy()\n",
    "binary_fields_df.stroke_ward_stay = binary_fields_df.stroke_ward_stay.apply(\n",
    "    lambda x: 0 if x == \"N\" else 1\n",
    ")\n",
    "binary_fields_df.IS_care_home_on_admission = (\n",
    "    binary_fields_df.IS_care_home_on_admission.apply(lambda x: 0 if x == \"N\" else 1)\n",
    ")\n",
    "binary_fields_df.IS_care_home_on_discharge = (\n",
    "    binary_fields_df.IS_care_home_on_discharge.apply(lambda x: 0 if x == \"N\" else 1)\n",
    ")\n",
    "binary_fields_df.IS_major = binary_fields_df.IS_major.map({\"Y\": 1, \"N\": 0})\n",
    "# create new fields\n",
    "binary_fields_df[\"IS_illness_not_injury\"] = binary_fields_df[\"Illness Injury Flag\"].map(\n",
    "    {\"Illness\": 1, \"Injury\": 0}\n",
    ")\n",
    "binary_fields_df[\"IS_elective\"] = binary_fields_df.elective_or_non_elective.map(\n",
    "    {\"Non-elective admission\": 0, \"Elective admission\": 1}\n",
    ")\n",
    "# drop old\n",
    "binary_fields_df.drop(\n",
    "    columns=[\"Illness Injury Flag\", \"elective_or_non_elective\"], inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1650449163825
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# check new binary fields\n",
    "for field in [\n",
    "    \"stroke_ward_stay\",\n",
    "    \"IS_care_home_on_admission\",\n",
    "    \"IS_care_home_on_discharge\",\n",
    "    \"IS_illness_not_injury\",\n",
    "    \"IS_elective\",\n",
    "    \"IS_major\",\n",
    "]:\n",
    "    print(\n",
    "        f\"{field} has {binary_fields_df[field].isnull().sum()} null values and values:\"\n",
    "    )\n",
    "    print(binary_fields_df[field].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Check genders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1650449381429
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# there are only 13 \"not specified\" gender, all others are M/F\n",
    "binary_fields_df.PATIENT_GENDER_CURRENT_DESCRIPTION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1650449397228
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# drop \"not specified\" values\n",
    "genders_df = binary_fields_df.drop(\n",
    "    labels=binary_fields_df[\n",
    "        binary_fields_df.PATIENT_GENDER_CURRENT_DESCRIPTION == \"Not specified\"\n",
    "    ].index\n",
    ")\n",
    "genders_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final data checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1650449397450
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# check null values\n",
    "# there are still some columns with majority (~400k) values null; these can be encoding in a null field during modelling e.g. ae_arrival_mode\n",
    "genders_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1650449441282
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# plot null values\n",
    "sns.set(rc={\"figure.figsize\": (15, 8)})\n",
    "sns.heatmap(genders_df.isnull(), cbar=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1650449441532
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Export data (outside git tree)\n",
    "genders_df.to_parquet(\"../../data/clean-data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export cols/descriptions for Excel/Google Sheets import (inside git tree)\n",
    "genders_df.dtypes.to_csv(\"../data/cols.csv\")\n",
    "genders_df.describe().to_csv(\"../data/describe.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
